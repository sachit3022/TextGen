{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(4,3,2)\n",
    "p = torch.rand(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "t.repeat(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 1, 0, 1],\n",
       "          [1, 0, 0, 1],\n",
       "          [0, 1, 1, 0]],\n",
       " \n",
       "         [[0, 0, 1, 1],\n",
       "          [0, 1, 0, 1],\n",
       "          [0, 1, 0, 0]]]),\n",
       " tensor([[[0, 1],\n",
       "          [1, 0],\n",
       "          [0, 1]],\n",
       " \n",
       "         [[0, 1],\n",
       "          [0, 1],\n",
       "          [1, 0]],\n",
       " \n",
       "         [[0, 0],\n",
       "          [0, 1],\n",
       "          [0, 1]],\n",
       " \n",
       "         [[1, 1],\n",
       "          [0, 1],\n",
       "          [0, 0]]]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.randint(0,2,(2,3,4))\n",
    "new_o = o\n",
    "o,new_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "EinopsError",
     "evalue": " Error while processing rearrange-reduction pattern \"b c d -> (b h) c u\".\n Input tensor shape: torch.Size([2, 3, 4]). Additional info: {'h': 2, 'u': 2}.\n Identifiers only on one side of expression (should be on both): {'d', 'h', 'u'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/einops/einops.py:522\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    521\u001b[0m shape \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mshape(tensor)\n\u001b[0;32m--> 522\u001b[0m recipe \u001b[38;5;241m=\u001b[39m _prepare_transformation_recipe(pattern, reduction, axes_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(axes_lengths), ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(shape))\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _apply_recipe(\n\u001b[1;32m    524\u001b[0m     backend, recipe, cast(Tensor, tensor), reduction_type\u001b[38;5;241m=\u001b[39mreduction, axes_lengths\u001b[38;5;241m=\u001b[39mhashable_axes_lengths\n\u001b[1;32m    525\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/einops/einops.py:312\u001b[0m, in \u001b[0;36m_prepare_transformation_recipe\u001b[0;34m(pattern, operation, axes_names, ndim)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(difference) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentifiers only on one side of expression (should be on both): \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(difference))\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m operation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepeat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mEinopsError\u001b[0m: Identifiers only on one side of expression (should be on both): {'d', 'h', 'u'}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m einops\u001b[38;5;241m.\u001b[39mrearrange(o,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb c d -> (b h) c u\u001b[39m\u001b[38;5;124m'\u001b[39m,h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,u\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/einops/einops.py:591\u001b[0m, in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrearrange\u001b[39m(tensor: Union[Tensor, List[Tensor]], pattern: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maxes_lengths) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    537\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m    einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors.\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m    This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m \n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduce(tensor, pattern, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrearrange\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maxes_lengths)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/einops/einops.py:533\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Input is list. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdditional info: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(axes_lengths)\n\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n",
      "\u001b[0;31mEinopsError\u001b[0m:  Error while processing rearrange-reduction pattern \"b c d -> (b h) c u\".\n Input tensor shape: torch.Size([2, 3, 4]). Additional info: {'h': 2, 'u': 2}.\n Identifiers only on one side of expression (should be on both): {'d', 'h', 'u'}"
     ]
    }
   ],
   "source": [
    "einops.rearrange(o,'b c d -> (b h) c u',h=2,u=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "queries = torch.rand(1,2,4)\n",
    "keys = torch.rand(1,3,4)\n",
    "values = torch.rand(1,3,4)\n",
    "head_size = 2\n",
    "num_heads = 2\n",
    "q_batch_size,q_context_len, hidden_size = queries.shape\n",
    "kv_batch_size,kv_context_len, hidden_size = keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q,K,V = nn.Linear(hidden_size,hidden_size,bias=False),nn.Linear(hidden_size,hidden_size,bias=False),nn.Linear(hidden_size,hidden_size,bias=False)\n",
    "\n",
    "\n",
    "q = Q(queries)\n",
    "q = q.transpose(0,1).contiguous().view(q_context_len,q_batch_size*num_heads,head_size).transpose(0,1).contiguous() #view(q.shape[0]*self.num_heads, self.hidden_size,self.head_size )\n",
    "\n",
    "\n",
    "k = K(keys)\n",
    "k = k.transpose(0,1).contiguous().view(kv_context_len,kv_batch_size*num_heads,head_size).transpose(0,1).contiguous() #view(q.shape[0]*self.num_heads, self.hidden_size,self.head_size )\n",
    "\n",
    "v = V(values)\n",
    "v = v.transpose(0,1).contiguous().view(kv_context_len,kv_batch_size*num_heads,head_size).transpose(0,1).contiguous() #view(q.shape[0]*self.num_heads, self.hidden_size,self.head_size )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4568, -0.4133],\n",
       "          [-0.4059, -0.5416]],\n",
       " \n",
       "         [[ 0.3154,  0.5734],\n",
       "          [ 0.0683,  0.5658]]], grad_fn=<CloneBackward0>),\n",
       " tensor([[[-0.0158,  0.0611],\n",
       "          [-0.0396, -0.0120],\n",
       "          [ 0.0253, -0.1597]],\n",
       " \n",
       "         [[-0.3343,  0.2251],\n",
       "          [-0.3991,  0.0953],\n",
       "          [-0.4120, -0.0413]]], grad_fn=<CloneBackward0>),\n",
       " tensor([[[-0.5666,  0.1705],\n",
       "          [-0.4925,  0.0933],\n",
       "          [-0.3296,  0.2364]],\n",
       " \n",
       "         [[-0.0453,  0.1259],\n",
       "          [-0.0343,  0.1458],\n",
       "          [-0.0801,  0.3564]]], grad_fn=<CloneBackward0>))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q,k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000,   -inf,   -inf],\n",
       "         [0.6290, 0.3710,   -inf]],\n",
       "\n",
       "        [[1.0000,   -inf,   -inf],\n",
       "         [0.4855, 0.5145,   -inf]],\n",
       "\n",
       "        [[1.0000,   -inf,   -inf],\n",
       "         [0.4677, 0.5323,   -inf]],\n",
       "\n",
       "        [[1.0000,   -inf,   -inf],\n",
       "         [0.5466, 0.4534,   -inf]]], grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tril(attention)\n",
    "attention[mask==0] = -float('inf')\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000],\n",
       "         [0.4877, 0.5123, 0.0000]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000],\n",
       "         [0.5195, 0.4805, 0.0000]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = torch.bmm(q,k.transpose(-2,-1)) \n",
    "mask = torch.tril(attention)\n",
    "attention[mask==0] = -float('inf')\n",
    "attention = F.softmax(attention,dim=-1)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11363736"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.0764*0.3244 + 0.0004* 0.3340  -0.2605* 0.3416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5666,  0.1705],\n",
       "         [-0.5286,  0.1309]],\n",
       "\n",
       "        [[-0.0453,  0.1259],\n",
       "         [-0.0400,  0.1355]]], grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = torch.bmm(attention,v)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5666,  0.1705, -0.0453,  0.1259],\n",
       "         [-0.5286,  0.1309, -0.0400,  0.1355]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0781)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor([0.0614,  0.3348]) * torch.tensor([0.4157,  0.1569])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0614,  0.3348,  0.3951, -0.0715],\n",
       "         [-0.0674,  0.3227,  0.6149, -0.2674]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
